[{"categories":["linux"],"content":"CMD和ENTRYPOINT  cmd ,在运行时可以被覆盖\n两个同时存在时，cmd中的内容会被当做参数传递到entrypoint中\n ","date":"2021-07-19","permalink":"/posts/docker/base/","series":["docker"],"tags":["linux","docker"],"title":"docker"},{"categories":["linux"],"content":"1.制作小镜像 1.1基础镜像的选择  alpine busybox scratch：空的镜像，什么都没有 debian 如果用到glibc，可以使用各种slim镜像版本：例如node:slim  1.2使用多阶段构建  编译和最终的操作分开 多阶段构建时，如果使用了自定义的镜像，自定义的镜像被修改了，可以在build的时候添加参数 \u0026ndash;pull来拉取最新的版本\n ","date":"2021-07-19","permalink":"/posts/docker/dockerfile/","series":["docker"],"tags":["dockerfile","docker"],"title":"docker"},{"categories":["linux"],"content":"1. 基础环境搭建 1.1 mysql mkdir -p /data/docker/mysql/data docker run --name mysql -v /data/docker/mysql/data:/var/lib/mysql -p 3 -e MYSQL_ROOT_PASSWORD=root -d mysql:5.7.35 ","date":"2021-07-19","permalink":"/posts/docker/env/","series":["docker"],"tags":["linux","docker"],"title":"docker"},{"categories":["k8s"],"content":"1. 组件 1.1 master节点  kube-APIServer:集群的控制中枢，各个模块之间信息交互都需要经过Kube-APIServer，同时它也是集群管理、资源配置、整个集群安全机制的入口。 Controller-Manager:集群的状态管理器，保证Pod或其他资源达到期望值，也是需要和APIServer进行通信，在需要的时候创建、更新或删除它所管理的资源。 Scheduler:集群的调度中心，它会根据指定的一系列条件，选择一个或一批最佳的节点，然后部署我们的Pod。 Etcd:键值数据库，报错一些集群的信息，一般生产环境中建议部署三个以上节点（奇数个,建议和Master分开，单独部署）。  1.2 node节点  kubelet:负责监听节点上Pod的状态，同时负责上报节点和节点上面Pod的状态，负责与Master节点通信，并管理节点上面的Pod。 kube-proxy:负责Pod之间的通信和负载均衡，将指定的流量分发到后端正确的机器上。   master节点也可以安装kubelet和kube-proxy，并配置污点，不运行node上的pod\n 1.2.1查看Kube-proxy工作模式： curl 127.0.0.1:10249/proxyMode\n Ipvs：监听Master节点增加和删除service以及endpoint的消息，调用Netlink接口创建相应的IPVS规则。通过IPVS规则，将流量转发至相应的Pod上。 Iptables：监听Master节点增加和删除service以及endpoint的消息，对于每一个Service，他都会场景一个iptables规则，将service的clusterIP代理到后端对应的Pod。  1.3 其他组件  Calico：符合CNI标准的网络插件，给每个Pod生成一个唯一的IP地址，并且把每个节点当做一个路由器。(Cilium性能更好，可以替代calico) CoreDNS：用于Kubernetes集群内部Service的解析，可以让Pod把Service名称解析成IP地址，然后通过Service的IP地址进行连接到对应的应用上。 Docker：容器引擎，负责对容器的管理。  2. 资源隔离    资源名称 是否namespace隔离     Pod 是   RC和RS 是   pv 否   RBAC 否   pvc 是                             3. 常用命令 # 查看pod.spec的完整配置字段 kubectl explain pod.spec 4.调度管理 4.1 资源分配调度 ###4.1.1 基于pod中容器request资源“总和”调度\n resources。limits影响pod的运行资源上限，不影响调度 initContainer取最大值，container取累加值，最后取大者。即Max(Max(initContainers.requests),Sum(containers.requests))   initContainer运行后会退出，所以不需要累加\n  未指定request，按0资源需求进行调度  4.1.2 基于资源申明的调度，而非实际占用  不依赖监控，系统不会过于敏感 能否调度成功：pod.request\u0026lt;node.allocatable -node.request;pod的请求量 小于（node的分配量-已经调度的pod的量）  4.1.3 资源分配的盒子模型 ###4.1.4资源分配相关算法\n generalPredicates(主要是PodFitsResources)，检查余量，cpu内存硬盘是否满足 LeastRequestedPriotity，最少被调度pod的节点 BalanceResourceAllocation,平衡节点cpu/mem消耗比例  4.2 高级调度 4.2.1 nodeSelector:将pod调度到指定的node上  匹配node.lables,完全匹配\n 4.2.2 nodeAffinity：nodeselector升级版  与nodeSelector关键差异，是\n  引入运算符：In，NotIN（lableSelector语法）\n  支持枚举lable可能的取值，如zone in [az1,az2 \u0026hellip;]\n  支持硬性过滤和软性评分\n  硬性过滤规则支持指定 多条件之间的逻辑或运算\n  软性评分规则支持 设置条件权重值\n   4.2.3 podAffinity:让某些pod分布在同一组上Node上  与nodeAffinity的关键差异\n 定义在PodSpec中，亲和和反亲和规则具有对称性 labelSelector的匹配对象为Pod 对node分组依据label-key=topologKey，每个label-value取值为一组 硬性过滤规则，条件之间只有逻辑与运算   4.2.4podAntiAffinity：避免某些pod分布在同一组Node上  与podAffinity的匹配过程相同，最终的调度结果取反\n 4.2.5 手动调度pod   nodeName:直接指定运行的nodeName；\n 适用于调度器不工作，临时救急;\n封装实现自定义的调度器\n   DaemonSet：每个节点来一份\n 适用于每个节点都需要部署的agent等\n   4.2.6 Taints：避免Pod调度到特定Node上  带effect的特殊label，对Pod有排斥星   硬性排斥：NoSchedule\n软性排斥 PreferNoSchedule\n 系统创建的taint附带时间戳   effect为NoExecute\n便于触发对pod的超时驱逐\n 典型用法：预留特殊节点做特殊用途\n# 给node添加taint kubectl taint node node-n1 foo=bar:NoSchedule # 删除taint kubectl taint node node-n1 foo:Noschedule- 4.2.7 Tolerations：允许Pod调度到有特定taints的Node上 4.3 调度失败的原因分析  查看调度结果  kubectl get pod [podname] -o wide   查看调度失败的原因\nkubectl describe pod [podname] 4.4 多调度器  使用场景：集群中存在多个调度器，分别处理不同类型的作业调度 使用限制：建议对弄的做资源池划分，避免调度结果写入冲突  4.5 自定义调度器配置 \u0026ndash;policy-config-file自定义调度器加载的算法，或者调整排序算法权重\n# 查询多调度器配置 kube-scheduler --help   5.监控  ```shell # 查看集群状态 kubectl cluster-info kubectl cluster-info dump \u0026gt;info.txt # 查看pod详情 kubectl describe pod #占用资源排序 kubectl top pod ｛podName｝ # 监控资源运行过程 kubectl get pod ｛podName｝ --watch ```  ​ ​\n```shell # 日志查看 # 组件日志 /var/log/kube-apiserver.log /var/log/kube-proxy.log /var/log/kube-controller-manager.log /var/log/kubelet.log # 使用systemd管理 journalctl -u kubelet #使用k8s插件部署 kubectl logs kube-proxy # k8s应用日志 #获取容器的日志 # 1.从容器标准输出截获 kubectl logs -f {podname} -c {container name} #或者使用docker命令 docker logs -f {container Name} # 2.直接进入容器内查看日志 kubectl exec -it {pod} -c {container} /bin/sh docker exec -it {container} /bin/sh # 3.挂载到主机上的日志 tail -f /log #主机挂载的目录 ``` 6 Deployment 升级与回滚  ```shell #创建deployment #可以使用yaml，重点配置replicas和image字段 kubectl run ｛deployment｝-image={image} -replicas={rep.} #升级deployment kubectl set image deployment/nginx-deployment nginx=nginx:1.9.1 kubectl set resources deploument/nginx-deployment -c=nginx --limits=cpu=200m,memory=521Mi ``` ```shell # 暂停deployment：不计入升级历史 kubectl rollout pause deployment/nginx-deployment # 恢复deployment kubectl rollout resume deployment/nginx-deployment # 查询升级状态 kubectl rollout status deployment/nginx-deployment # 查询升级历史 kubectl rollout history deployment/nginx-deployment kubectl rollout history deployment/nginx-deployment --revision=2 # 回滚 kubectl rollout undo deployment/nginx-deployment --通-revision=2 # 应用弹性伸缩 kubectl scale deployment nginx-doployment --replicas=10 #自动伸缩，需要对接监控 kubectl autoscale deployment nginx-deployment--min=10 --max=15 --cpu-percent=80 ``` ```shell # 应用自恢复（重启策略+探针） 使用restartPolicy + livenssProbe ```  7. 网络 7.1 pod网络  一个pod一个ip   每个pod独立ip，pod内所有容器共享网络namespace（同一个ip） 容器之间直接通讯，不需要nat Node和容器直接通信，不需要nat 其他容器和容器自身看到的ip是一样的  集群内访问走service，集群外访问走ingress CNI（container network interface）用于篇日志pod网络，不支持docker网络  7.2 service  clusterIp nodePort :创建后也被分配了clusterip headless service：类型为clusterIp ，但是clusterIp 为none  ingress  ingress是授权入站连接到达集群服务的规则集合\n 支持通过url方式将service暴露到k8s集群外，service之上的L7访问入库 支持自定义service的访问策略 提供按域名访问的虚拟主机功能 支持tls   k8s dns  解析pod和service的域名，k8s集群内pod使用\n通过CoreDNS实现（kube-dns已经废弃）\n 对Service  A记录  # 普通service my-svc.my-namespace.svc.cluster.local #cluster ip #headless service my-svc.my-namespace.svc.cluster.local # 后端ip列表 SRV记录  _my-port-name._my-port-protocol.my-namespace.svc.cluster.local # service port 对pod  A记录  pod-ip.my-namespace.pod.cluster.local #pod ip 在pod spec 指定hostname和subdomain  hostname.subdomain.my-namespace.pod.cluster.local # pod ip 查看dns  nslookup  #需要安装 nslookup wget https://kubernetes.io/examples/admin/dns/busybox.yaml # 运行容器 kubectl create -f busybox.yaml # 查看kubernetes.default域名 kubectl exec -it busybox -- nslookup kubernetes.default Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local Name: kubernetes.default Address 1: 10.96.0.1 kubernetes.default.svc.cluster.local 8. 存储管理 8.1 普通存储卷volume  存储没有单独资源对象，与pod的生命周期一起\ndeployment应用建议使用普通卷\n 8.2 持久化存储卷pv  存储系统与应用系统区分开，单独资源对象，它不直接和pod发生关系，通过另一个资源对象pvc来绑定\nstatefulset应用建议使用持久卷\n  静态模式   除了创建pvc外，还需要手动创建pv\n 动态模式   只需要创建pvc，系统根据pvc自动创建pv\n 9. 安全管理 9.1 安全全景图  部署态的安全控制    认证 鉴权 Admission（准入控制） Pod SecurityContext    运行态的安全控制    Network policy   9.2 认证 9.3 鉴权 9.4 admission 9.5 安全的持久化保存键值etcd 9.6 安全上下文（pod securityContext） 9.7 Network Policy 其他 1.preSet\n在preSet中，同一个主机路径，不能挂载到2个路径上，必须使用2个volumes来挂载\nPs：单独创建pod是可以这么操作的\n错误的配置：如下图\n","date":"2021-07-19","permalink":"/posts/k8s/base/","series":["k8s"],"tags":["k8s"],"title":"docker"},{"categories":["tool"],"content":"1. hugo安装配置 1.1 下载hugo  下载 hugo\r,并配置环境变量  运行demo  cd e:workspace/workspace-notes/ hugo new site notes cd notes git submodule add https://github.com/razonyang/hugo-theme-bootstrap themes/hugo-theme-bootstrap mkdir config cp -a themes/hugo-theme-bootstrap/exampleSite/config/* ./config #复制exampleSite\\content\\zh-cn 中的目录到content\\下,然后按照自己的需求修改 1.2 hugo配置 配置文件位置为项目的根目录下的config.toml\nbaseURL = \u0026#34;https://xiangguangsheng.github.io/\u0026#34; languageCode = \u0026#34;zh-cn\u0026#34; title = \u0026#34;james的个人主页\u0026#34; publishDir = \u0026#34;docs\u0026#34; #修改了默认的发布目录 1.3 GitHub pages配置  新建仓库 添加pages配置   下图1中的仓库名称，必须为：xxx.github.io,其中xxx为您的账号名称\n 1.4 访问页面   提交代码到GitHub\n  直接访问 https://xiangguangsheng.github.io/\r  ","date":"2021-07-19","permalink":"/posts/tool/hugo/","series":["tool"],"tags":["hugo","github pages"],"title":"hugo"},{"categories":["k8s"],"content":"1. node 1.1 master节点  kube-APIServer:集群的控制中枢，各个模块之间信息交互都需要经过Kube-APIServer，同时它也是集群管理、资源配置、整个集群安全机制的入口。 Controller-Manager:集群的状态管理器，保证Pod或其他资源达到期望值，也是需要和APIServer进行通信，在需要的时候创建、更新或删除它所管理的资源。 Scheduler:集群的调度中心，它会根据指定的一系列条件，选择一个或一批最佳的节点，然后部署我们的Pod。 Etcd:键值数据库，报错一些集群的信息，一般生产环境中建议部署三个以上节点（奇数个,建议和Master分开，单独部署）。  1.2 node节点  kubelet:负责监听节点上Pod的状态，同时负责上报节点和节点上面Pod的状态，负责与Master节点通信，并管理节点上面的Pod。 kube-proxy:负责Pod之间的通信和负载均衡，将指定的流量分发到后端正确的机器上。   master节点也可以安装kubelet和kube-proxy，并配置污点，不运行node上的pod\n 1.2.1查看Kube-proxy工作模式： curl 127.0.0.1:10249/proxyMode\n Ipvs：监听Master节点增加和删除service以及endpoint的消息，调用Netlink接口创建相应的IPVS规则。通过IPVS规则，将流量转发至相应的Pod上。 Iptables：监听Master节点增加和删除service以及endpoint的消息，对于每一个Service，他都会场景一个iptables规则，将service的clusterIP代理到后端对应的Pod。  1.3 其他组件  Calico：符合CNI标准的网络插件，给每个Pod生成一个唯一的IP地址，并且把每个节点当做一个路由器。(Cilium性能更好，可以替代calico) CoreDNS：用于Kubernetes集群内部Service的解析，可以让Pod把Service名称解析成IP地址，然后通过Service的IP地址进行连接到对应的应用上。 Docker：容器引擎，负责对容器的管理。  2. pod    资源名称 是否namespace隔离     Pod 是   RC和RS 是   pv 否   RBAC 否   pvc 是                             其他 1.preSet\n在preSet中，同一个主机路径，不能挂载到2个路径上，必须使用2个volumes来挂载\nPs：单独创建pod是可以这么操作的\n错误的配置：如下图\n","date":"2021-07-19","permalink":"/posts/k8s/kind/","series":["k8s"],"tags":["k8s"],"title":"k8s kind"},{"categories":["linux"],"content":"1.shell常用快捷键 1.1 光标移动 * ctrl + \u0026lt; 移动到前一个单词开头\r* ctrl + \u0026gt; 移动到后一个单词结尾\r* ctrl + A 移动到开头\r* ctrl + E 移动到结尾\r* alt + B 向左移动一个单词\r* alt + F 向右移动一个单词\rctrl + B 向左移动一个字符\rctrl + F 向右移动一个字符\resc + B 向左移动一个单词\resc + F 向右移动一个单词\rctrl + XX 在上次光和当前光标所在字符间跳转\resc + T 交换光标位置前的两个单词\r1.2 删除 * ctrl + K 删除光标后所有字符(剪切)\r* ctrl + U 删除光标前所有字符(剪切)\r* ctrl + W 删除光标前一个单词\rctrl + D 删除光标所在字符(光标右侧)\rctrl + H 删除光标前字符(光标左侧)\r1.3 撤销 * ctrl + _ 撤销操作\r* ctrl + Y 粘贴ctrl+U/K剪切的内容\rctrl + ? 撤消前一次输入\ralt + R 撤消前一次动作\r1.4 替换 * ctrl + T 将光标当前字符与前面一个字符替换\r1.5 历史命令编辑 * ctrl + P 上条输入的命令(相当于上键)\r* ctrl + N 上条历史命(相当于下键)\r* alt + \u0026gt; 上一次执行命令\r* ctrl + R 输入单词搜索历史命令\r1.6 控制命令 * ctrl + L 清除屏幕\rctrl + S 锁住终端，阻止屏幕输出\rctrl + Q 解锁终端，允许屏幕输出\rctrl + C 终止命令\u0026amp;另起一行\rctrl + I 补全功能(类似TAB)\rctrl + O 重复执行命令\ralt + \u0026lt;数字\u0026gt; 操作的次数\rctrl + Z 挂起\r1.7 !命令 * !! 执行上条命令\r* !-n 执行前n条命令\r2.shell 基础 2.1 变量 2.1.1 自定义变量  定义变量：变量名=变量值 （等号前后不能有空格） 引用变量：\\$变量名和\\${变量名},区别：基本相同，${变量名}可以用在字符串模板中 查看变量：echo $变量名，set 显示所有的变量，包括自定义变量和系统变量 取消变量：unset 变量名，作用范围，当前shell中有效  2.1.2 系统变量  定义系统变量：export 变量名=变量值,将自定义变量转为环境变量 引用系统变量：\\$变量名和\\${变量名},区别：基本相同，${变量名}可以用在字符串模板中 查看系统变量：echo $变量名，env显示所有系统变量 取消系统变量：unset 变量名，作用范围，当前shell和子shell中有效  2.1.3 位置参数变量 脚本参数传参$1 $2 $3 $4 $5 $6 $7 $8 $9 ${10} \n2.1.3 预先定义变量  $0脚本名称\n$*所有参数\n$@所有参数\n$#参数个数\n$$当前进程pid\n$!上个后台经常pid\n$?上个命令返回值，0表示成功\n 脚本参数传参$1 $2 $3 $4 $5 $6 $7 $8 $9 ${10} \n#变量赋值，=号前后不能有空格 # 变量的解析，建议用$(),不建议使用` v1=`date +%F` v2=$(date +%F) 2.2 引号的区别    符号 含义 实例     单引号' 所见即所得    双引号\u0026quot; 会解析变量    反引号` 会执行命令同$()     2.3 数字运算   使用$(()),例如$((1+2))\n  使用$[],例如：$[1+2]\n  expr, 例如：expr 1+2\n  let，例如：let num=1+2\n  2.4 $  ${变量名-默认变量值}，当变量没有设置值时（或者使用了unset 变量名 ）,会显示默认变量值；当有变量值（包括空值），不会显示默认值 ${变量名:-默认变量值}，当变量没有设置值时（包括空值 ）,会显示默认变量值；当有变量值（不包括空值），不会显示默认值  2.5 命令执行  命令1 ；命令2 :命令1和命令2都会执行 命令1 \u0026amp;\u0026amp; 命令2 :命令1执行成功才会执行命令2 命令1 || 命令2 :命令1执行失败才会执行命令2  2.6 条件测试  test 条件表达式 [ 条件表达式 ] [[ 条件表达式 ]]   [是个命令，所以，[ 条件表达式 ] 表达式前后都要有空格\n 2.7 文件测试  [ -e dir|file ]: 是否存在dir目录 或者file文件 [ -d dir ]: 是否存在dir目录 [ -f file ]: 是否存在file文件 [ -r file ]: 是否有读权限 [ -w file ]: 是否有写权限 [ -x file ]: 是否有执行权限 [ -L file ]: 是否为链接文件  2.8 数值比较  [ 1 -gt 10 ]: 大于 [ 1 -lt 10 ]: 小于 [ 1 -eq 10 ]: 等于 [ 1 -ne 10 ]: 不等于 [ 1 -ge 10 ]: 大于等于 [ 1 -le 10 ]: 大于等于  2.9 if语句 if [ 条件语句 ];then echo \u0026#34;条件1\u0026#34; elif [ 条件语句 ];then echo \u0026#34;条件1\u0026#34; elif [ 条件语句 ];then echo \u0026#34;条件1\u0026#34; else echo \u0026#34;条件1\u0026#34; fi 2.10 case语句 case 变量 in 值1) echo \u0026#34;1\u0026#34; ;; 值2) echo \u0026#34;2\u0026#34; ;; *) echo \u0026#34;*\u0026#34; esac 2.11 for循环 for 变量 in [ 取值列表 ] do echo \u0026#34;1\u0026#34; done 2.12 while循环 while 条件测试 do echo \u0026#34;1\u0026#34; done 2.13 shell内置命令  break 跳出当前循环 continue 执行下次循环 exit 退出整个程序  3.1 子shell { 命令 }\u0026amp; #命令会在子shell中执行，可以使用wait 还等待执行完成 ","date":"2021-07-19","permalink":"/posts/linux/shell/","series":["linux"],"tags":["linux","shell"],"title":"shell"},{"categories":["linux"],"content":"1.安装后配置 1.1 更新系统 # 列出可更新软件列表 sudo apt update # 更新软件 sudo apt upgrade # 清除旧的组件 sudo apt autoremove #更新系统版本 sudo apt-get dist-upgrade 1.2 修改ip sudo vi /etc/netplan/00-installer-config.yaml network: ethernets: enp0s3: dhcp4: no addresses: [192.168.124.200/24] optional: true gateway4: 192.168.124.1 nameservers: addresses: [223.5.5.5,223.6.6.6] version: 2 sudo netplan apply 1.3 修改hostname vim /etc/cloud/cloud.cfg # 修改 preserve_hostname: true sudo hostnamectl set-hostname master sudo reboot 1.4 安装docker ##文档路径 https://docs.docker.com/engine/install/ubuntu/ # 1.安装依赖工具 sudo apt-get install \\  apt-transport-https \\  ca-certificates \\  curl \\  gnupg \\  lsb-release # 2.安装 Docker’s official GPG key  curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg # 3.设置标准仓库 echo \\  \u0026#34;deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs)stable\u0026#34; | sudo tee /etc/apt/sources.list.d/docker.list \u0026gt; /dev/null # 4.安装 sudo apt-get update sudo apt-get install docker-ce docker-ce-cli containerd.io # 指定安装版本（可选） # apt-cache madison docker-ce # sudo apt-get install docker-ce=\u0026lt;VERSION_STRING\u0026gt; docker-ce-cli=\u0026lt;VERSION_STRING\u0026gt; containerd.io #5.查看docker信息 sudo docker info #6. 配置docker sudo mkdir /etc/docker cat \u0026lt;\u0026lt;EOF | sudo tee /etc/docker/daemon.json { \u0026#34;registry-mirrors\u0026#34;:[\u0026#34;https://5m8lizc8.mirror.aliyuncs.com\u0026#34;], \u0026#34;exec-opts\u0026#34;: [\u0026#34;native.cgroupdriver=systemd\u0026#34;], \u0026#34;log-driver\u0026#34;: \u0026#34;json-file\u0026#34;, \u0026#34;log-opts\u0026#34;: { \u0026#34;max-size\u0026#34;: \u0026#34;100m\u0026#34; }, \u0026#34;storage-driver\u0026#34;: \u0026#34;overlay2\u0026#34; } EOF sudo systemctl enable docker sudo systemctl daemon-reload sudo systemctl restart docker #7.解决docker info 报错WARNING: No swap limit support vim /etc/default/grub #GRUB_CMDLINE_LINUX=配置项，原有的内容切记不要删除，在双引号内添加cgroup_enable=memory swapaccount=1 update-grub reboot 1.5 安装kubelet kubeadm kubectl   更新 apt 包索引并安装使用 Kubernetes apt 仓库所需要的包：\nsudo apt-get update sudo apt-get install -y apt-transport-https ca-certificates curl   下载 Google Cloud 公开签名秘钥：\ncurl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add -   添加 Kubernetes apt 仓库：\ncat \u0026lt;\u0026lt;EOF \u0026gt;/etc/apt/sources.list.d/kubernetes.list deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main EOF   更新 apt 包索引，安装 kubelet、kubeadm 和 kubectl，并锁定其版本：\nsudo apt-get update #列出所有的版本 sudo apt-cache madison kubeadm sudo apt-get install -y kubelet=1.21.4-00 kubeadm=1.21.4-00 kubectl=1.21.4-00 ##sudo apt-mark hold kubelet kubeadm kubectl systemctl daemon-reload systemctl enable kubelet systemctl start kubelet   1.6 安装集群 1.6.1 创建集群安装配置文件kubeadm-config.yaml（master节点） #通过如下指令创建默认的kubeadm-config.yaml文件 kubeadm config print init-defaults \u0026gt; kubeadm-config.yaml #默认文件如下 apiVersion: kubeadm.k8s.io/v1beta2 bootstrapTokens: - groups: - system:bootstrappers:kubeadm:default-node-token token: abcdef.0123456789abcdef ttl: 24h0m0s usages: - signing - authentication kind: InitConfiguration localAPIEndpoint: advertiseAddress: 1.2.3.4 bindPort: 6443 nodeRegistration: criSocket: /var/run/dockershim.sock name: node taints: null --- apiServer: timeoutForControlPlane: 4m0s apiVersion: kubeadm.k8s.io/v1beta2 certificatesDir: /etc/kubernetes/pki clusterName: kubernetes controllerManager: {} dns: type: CoreDNS etcd: local: dataDir: /var/lib/etcd imageRepository: k8s.gcr.io kind: ClusterConfiguration kubernetesVersion: 1.21.0 networking: dnsDomain: cluster.local serviceSubnet: 10.96.0.0/12 scheduler: {} #修改后如下 apiVersion: kubeadm.k8s.io/v1beta2 bootstrapTokens: - groups: - system:bootstrappers:kubeadm:default-node-token token: abcdef.0123456789abcdef ttl: 24h0m0s #加入集群token的过期时间 usages: - signing - authentication kind: InitConfiguration localAPIEndpoint: advertiseAddress: 192.168.124.200 #本机的ip，主节点的ip bindPort: 6443 nodeRegistration: criSocket: /var/run/dockershim.sock name: master #主机名 taints: #添加污点，master节点不部署容器 - effect: NoSchedule key: node-role.kubernetes.io/master --- apiServer: timeoutForControlPlane: 4m0s apiVersion: kubeadm.k8s.io/v1beta2 certificatesDir: /etc/kubernetes/pki clusterName: kubernetes controlPlaneEndpoint: \u0026#34;192.168.124.200:6443\u0026#34; # 主节点的地址，高可用的时候为虚拟IP和haproxy端口 controllerManager: {} dns: type: CoreDNS etcd: local: dataDir: /var/lib/etcd imageRepository: registry.aliyuncs.com/google_containers #替换为阿里云镜像 kind: ClusterConfiguration kubernetesVersion: 1.21.0 networking: dnsDomain: cluster.local serviceSubnet: 10.96.0.0/12 #service的网段 podSubnet: 172.168.0.0/12 #pod的网段 scheduler: {} #配置文件的版本和kubeadm版本不一致时可以使用 kubeadm config migrate --old-config kubeadm-config.yaml --new-config kubeadm-config-new.yaml # 查看需要拉取的镜像 kubeadm config images list --config kubeadm-config.yaml # 手动提前拉取要拉取的镜像，这步可以不操作，kubeadm init 时会自动拉取 kubeadm config images pull --config kubeadm-config.yaml #安装集群 kubeadm init --config kubeadm-config.yaml --upload-certs # 如果出错了，可以重置集群 kubeadm reset ## 初始化成功的提示信息 Your Kubernetes control-plane has initialized successfully! ## 普通用户管理集群，需要拷贝 /etc/kubernetes/admin.con 到.kube/config To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config ## root管理集群，只需要配置环境变量即可 Alternatively, if you are the root user, you can run: export KUBECONFIG=/etc/kubernetes/admin.conf You should now deploy a pod network to the cluster. Run \u0026#34;kubectl apply -f [podnetwork].yaml\u0026#34; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ You can now join any number of the control-plane node running the following command on each as root: # 主节点加入到集群中的命令，--control-plane 只有主节点才会有 kubeadm join 192.168.124.200:6443 --token abcdef.0123456789abcdef \\ \t--discovery-token-ca-cert-hash sha256:7a3bec57076a1dd4b7f9c3f7b5acebab29f669e6dc9dc94bc3e0b489e504915c \\ \t--control-plane --certificate-key b127516b8d4c04890a84f600549d117a5d7b606e4b092c9869ad248ca0aa41cb Please note that the certificate-key gives access to cluster sensitive data, keep it secret! As a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use \u0026#34;kubeadm init phase upload-certs --upload-certs\u0026#34; to reload certs afterward. Then you can join any number of worker nodes by running the following on each as root: # node节点加入到集群中的命令， kubeadm join 192.168.124.200:6443 --token abcdef.0123456789abcdef \\ \t--discovery-token-ca-cert-hash sha256:7a3bec57076a1dd4b7f9c3f7b5acebab29f669e6dc9dc94bc3e0b489e504915c #admin.conf 保存的是集群的信息，kubectl 操作过去集群信息，就是通过这个文件 cat \u0026lt;\u0026lt;EOF \u0026gt;\u0026gt; ~/.bashrc export KUBECONFIG=/etc/kubernetes/admin.conf EOF source ~/.bashrc root@master:~# kubectl get node NAME STATUS ROLES AGE VERSION master NotReady control-plane,master 9m56s v1.21.4 root@master:~# kubectl get pod -A -o wide NAMESPACE NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES kube-system coredns-59d64cd4d4-7x2zl 0/1 Pending 0 12m \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system coredns-59d64cd4d4-cbdk6 0/1 Pending 0 12m \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system etcd-master 1/1 Running 0 12m 192.168.124.200 master \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system kube-apiserver-master 1/1 Running 0 12m 192.168.124.200 master \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system kube-controller-manager-master 1/1 Running 0 12m 192.168.124.200 master \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system kube-proxy-72zjr 1/1 Running 0 12m 192.168.124.200 master \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system kube-scheduler-master 1/1 Running 0 12m 192.168.124.200 master \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; #coredns 的STATUS为Pending，是因为网络组建没有装，装了网络组件后，状态变为正常 1.6.2 node节点加入到集群（node节点） kubeadm join 192.168.124.200:6443 --token abcdef.0123456789abcdef \\ \t--discovery-token-ca-cert-hash sha256:7a3bec57076a1dd4b7f9c3f7b5acebab29f669e6dc9dc94bc3e0b489e504915c 1.6.3 组建集群的token过期处理 # 生成node节点加入集群的token root@master:~# kubeadm token create --print-join-command kubeadm join 192.168.124.200:6443 --token 6vtaym.uus1ojfhejme92c7 --discovery-token-ca-cert-hash sha256:7a3bec57076a1dd4b7f9c3f7b5acebab29f669e6dc9dc94bc3e0b489e504915c #生成master节点加入的token，master节点比node节点多了个--control-plane的key root@master:~# kubeadm init phase upload-certs --upload-certs I0819 01:03:18.692929 28537 version.go:254] remote version is much newer: v1.22.0; falling back to: stable-1.21 [upload-certs] Storing the certificates in Secret \u0026#34;kubeadm-certs\u0026#34; in the \u0026#34;kube-system\u0026#34; Namespace [upload-certs] Using certificate key: 8d8911281338fd20979a7bf4be9c103dd1499404afad592718efad837a8d9ac9 #组建主节点的加入命令 kubeadm join 192.168.124.200:6443 --token 6vtaym.uus1ojfhejme92c7 --discovery-token-ca-cert-hash sha256:7a3bec57076a1dd4b7f9c3f7b5acebab29f669e6dc9dc94bc3e0b489e504915c --control-plane --certificate-key 8d8911281338fd20979a7bf4be9c103dd1499404afad592718efad837a8d9ac9 #其他命令 #查看所有的sectet kubectl get secret -A #输出密钥信息 kubectl get secret -n kube-system bootstrap-token-6vtaym -oyaml= 1.6.4 安装网络组建calico ##文档位置 # https://docs.projectcalico.org/getting-started/kubernetes/self-managed-onprem/onpremises # 安装calico curl https://docs.projectcalico.org/manifests/calico-etcd.yaml -o calico.yaml #取消下面两行的注释，并将192.168.0.0/16 替换为kubeadm-config.yaml中的podSubnet 172.168.0.0/12 - name: CALICO_IPV4POOL_CIDR value: \u0026#34;172.168.0.0/12\u0026#34; #修改etcd的地址 #etcd_endpoints: \u0026#34;http://\u0026lt;ETCD_IP\u0026gt;:\u0026lt;ETCD_PORT\u0026gt;\u0026#34; etcd_endpoints: \u0026#34;https://192.168.124.200:2379\u0026#34; #etcd的证书配置 data: # Configure this with the location of your etcd cluster. #etcd_endpoints: \u0026#34;http://\u0026lt;ETCD_IP\u0026gt;:\u0026lt;ETCD_PORT\u0026gt;\u0026#34; etcd_endpoints: \u0026#34;https://192.168.124.200:2379\u0026#34; #etcd的地址，要使用https # If you\u0026#39;re using TLS enabled etcd uncomment the following. # You must also populate the Secret below with these files. etcd_ca: \u0026#34;/calico-secrets/etcd-ca\u0026#34; #打开注释 etcd_cert: \u0026#34;/calico-secrets/etcd-cert\u0026#34; #打开注释 etcd_key: \u0026#34;/calico-secrets/etcd-key\u0026#34; #打开注释 # 使用命令 替换密钥 cat \u0026lt;file\u0026gt; | base64 -w 0 apiVersion: v1 kind: Secret type: Opaque metadata: name: calico-etcd-secrets namespace: kube-system data: # Populate the following with etcd TLS configuration if desired, but leave blank if # not using TLS for etcd. # The keys below should be uncommented and the values populated with the base64 # encoded contents of each file that would be associated with the TLS data. # Example command for encoding a file contents: cat \u0026lt;file\u0026gt; | base64 -w 0 etcd-key: LS0tLS1CRUdJT...VORCBSU0EgUFJJVkFURSBLRVktLS0tLQo= #/etc/kubernetes/pki/etcd/server.key etcd-cert: LS0tLS1CRUdJTiBDRVJU...LS0tCg== #/etc/kubernetes/pki/etcd/server.crt etcd-ca: LS0tLS1CRUdJ...tLS0tLQo= #/etc/kubernetes/pki/etcd/ca.crt 1.6.4 coredns安装失败 calico安装后，coredns镜像拉取失败\n# 查看错误信息 kubectl describe pod coredns-59d64cd4d4-n46p6 -n kube-system # 手动拉取镜像地址，每个node节点都要执行 然后改名 docker pull registry.aliyuncs.com/google_containers/coredns:1.8.0 docker tag registry.aliyuncs.com/google_containers/coredns:1.8.0 registry.aliyuncs.com/google_containers/coredns:v1.8.0 # 删除错误的pod，k8s会自动重启pod，拉取镜像 kubectl delete pod coredns-59d64cd4d4-n46p6 -n kube-system 1.6.5 k8s命令自动补全 echo \u0026#34;source \u0026lt;(kubectl completion bash)\u0026#34; \u0026gt;\u0026gt; ~/.bashrc # 在您的 bash shell 中永久的添加自动补全 1.7 mertics-server wget https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml template: metadata: labels: k8s-app: metrics-server spec: containers: - args: - --cert-dir=/tmp - --secure-port=443 - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt # 添加证书，可能会导致获取不到度量指标 - --kubelet-use-node-status-port - --metric-resolution=15s image: k8s.gcr.io/metrics-server/metrics-server:v0.5.0 1.8 dashboard ","date":"2021-07-19","permalink":"/posts/linux/ubuntu/","series":["linux"],"tags":["linux","ubuntu"],"title":"shell"},{"categories":["tool"],"content":"1. Github访问慢处理办法 1.1 方法1：GitHub520(推荐)  下载SwitchHosts\r 按照下图配置SwitchHosts  url为：https://raw.hellogithub.com/hosts\n1.2 方法2：手动修改host方式  通过站长工具查询github的ip，http://tool.chinaz.com/dns   修改host文件（C:\\Windows\\System32\\drivers\\etc\\hosts），选择上图中速度最快的ip\n52.192.72.89 github.com\r  github.com的ip是动态变化的，经常需要重复上述步骤修改\n  2. Shadowsocks安装  centos8,使用了新的包管理工具dnf来代替yml，使用podman来代理docker\n 2.1 使用podman安装Shadowsocks的服务端 dnf install -y podman podman pull shadowsocks/shadowsocks-libev podman run -e PASSWORD=Td123456 -e METHOD=aes-256-gcm -p28080:8388 -p28080:8388/udp -d shadowsocks/shadowsocks-libev 2.2 安装Shadowsocks的客户端   下载并安装Shadowsocks客户端：https://github.com/shadowsocks/shadowsocks-windows/releases\n  如下图配置Shadowsocks客户端\n  ","date":"2021-07-19","permalink":"/posts/tool/proxy/","series":["tool"],"tags":["proxy","github","SwitchHosts","Shadowsocks"],"title":"代理"},{"categories":["Shortcode"],"content":"本文展示了如果使用 alert shortcode。\n{{\u0026lt; alert \u0026#34;Message\u0026#34; [type] \u0026gt;}}  The parameter type is optional. Default to info.\n Info {{\u0026lt; alert \u0026#34;Info\u0026#34; \u0026gt;}} Info\r\rSuccess {{\u0026lt; alert \u0026#34;Success\u0026#34; success \u0026gt;}} Success\r\rWarning {{\u0026lt; alert \u0026#34;Warning\u0026#34; warning \u0026gt;}} Warning\r\rDanger {{\u0026lt; alert \u0026#34;Danger\u0026#34; danger \u0026gt;}} Danger\r","date":"2020-10-22","permalink":"/posts/shortcodes/alert/","series":["用户手册"],"tags":["Alert"],"title":"Alert Shortcode"},{"categories":["Shortcode"],"content":"关于哔哩哔哩 shortcode 的详细使用说明。\n使用 {{\u0026lt; bilibili \u0026#34;video id\u0026#34; \u0026gt;}} 例子 \r","date":"2020-10-22","permalink":"/posts/shortcodes/bilibili/","series":null,"tags":["哔哩哔哩"],"title":"Bilibili Shortcode"},{"categories":["Shortcode"],"content":"关于 CodePen shortcode 的详细说明。\n使用 {{\u0026lt; codepen \u0026#34;id\u0026#34; \u0026gt;}} 例子 \r","date":"2020-10-22","permalink":"/posts/shortcodes/codepen/","series":null,"tags":["CodePen"],"title":"CodePen Shortcode"},{"categories":["Shortcode"],"content":"关于 JSFiddle shortcode 的详细说明。\n使用 {{\u0026lt; jsfiddle \u0026#34;user/id\u0026#34; \u0026gt;}} 例子 \r","date":"2020-10-22","permalink":"/posts/shortcodes/jsfiddle/","series":null,"tags":["JSFiddle"],"title":"JSFiddle Shortcode"},{"categories":["Shortcode"],"content":"关于 JSRun shortcode 的详细说明。\n使用 {{\u0026lt; jsrun \u0026#34;id\u0026#34; \u0026gt;}} 例子 \r","date":"2020-10-22","permalink":"/posts/shortcodes/jsrun/","series":null,"tags":["JSRun"],"title":"JSRun Shortcode"},{"categories":["Shortcode"],"content":"关于优酷 shortcode 的详细说明。\n使用 {{\u0026lt; youku \u0026#34;XNTQwMTgxMTE2\u0026#34; \u0026gt;}} 例子 \r","date":"2020-10-22","permalink":"/posts/shortcodes/youku/","series":null,"tags":["Youku"],"title":"优酷 Shortcode"},{"categories":["Shortcode"],"content":"关于爱奇艺 shortcode 的详细说明。\n使用 {{\u0026lt; iqiyi \u0026#34;vid\u0026#34; \u0026#34;tvid\u0026#34; \u0026gt;}} 例子 \r","date":"2020-10-22","permalink":"/posts/shortcodes/iqiyi/","series":null,"tags":["爱奇艺"],"title":"爱奇艺 Shortcode"},{"categories":["Shortcode"],"content":"关于网易云音乐 Shortcode 的详细使用说明。\n使用 {{\u0026lt; neteasemusic \u0026#34;id\u0026#34; [auto [type]] \u0026gt;}}    Parameter Description     auto The auto controls whether to autoplay. Boolean and optional, default to false.   type The type parameter is optional. Default to 2.    例子 \r","date":"2020-10-22","permalink":"/posts/shortcodes/neteasemusic/","series":null,"tags":["网易云音乐"],"title":"网易云音乐 Shortcode"},{"categories":["Shortcode"],"content":"关于腾讯视频 shortcode 的详细说明。\n使用 {{\u0026lt; tencentvideo \u0026#34;vid\u0026#34; \u0026gt;}} 例子 \r","date":"2020-10-22","permalink":"/posts/shortcodes/tencentvideo/","series":null,"tags":["腾讯视频"],"title":"腾讯视频 Shortcode"}]